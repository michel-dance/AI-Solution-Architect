{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AISA-DucHaba/AI-Solution-Architect/blob/main/Text_Moderation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WnEac7Fwdgw"
      },
      "source": [
        "# 🌻 Text Moderation\n",
        "\n",
        "---\n",
        "\n",
        "- Let's Rock and Roll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHGKa52qwsp7"
      },
      "source": [
        "- This NLP (Natural Language Processing) AI demonstration aims to prevent profanity, vulgarity, hate speech, violence, sexism, and other offensive language. It is not an act of censorship, as the final UI (User Interface) will give the reader, but not a young reader, the option to click on a label to read the toxic message.\n",
        "\n",
        "- The goal is to create a safer and more respectful environment for you, your colleages, and your family. This NLP app is 1 of 3 hands-on apps from the [\"AI Solution Architect,\"](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin) from ELVTR and Duc Haba.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUogjldqkhPn"
      },
      "source": [
        "# 😎 Instatiate Pluto, Monty is the name\n",
        "\n",
        "---\n",
        "\n",
        "- I use the Pluto object often in my coding. I created it as an opensource project.\n",
        "\n",
        "- Github: 'https://github.com/duchaba/pluto_happy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj2BqKWa1Osn"
      },
      "outputs": [],
      "source": [
        "%%capture log_pip_install_openai\n",
        "!pip install openai\n",
        "# and other deploy lib\n",
        "!pip install gradio\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf0BcIJ61fFn"
      },
      "outputs": [],
      "source": [
        "# %%write app.py\n",
        "import openai\n",
        "import gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKL-A7ysdYn_",
        "outputId": "6646b3e1-a582-43a8-e07b-ef938147f02b"
      },
      "outputs": [],
      "source": [
        "# check Git version, atleast version 2.34.1\n",
        "!git --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hsJlfdd6YT5",
        "outputId": "734c3594-5eb8-43db-e02a-c46abcd93bb2"
      },
      "outputs": [],
      "source": [
        "# large files\n",
        "!pip install lfs\n",
        "!git-lfs track *.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFhqm_V3LK0w"
      },
      "outputs": [],
      "source": [
        "# !jupyter nbextension enable hinterland/hinterland"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lopo_0f6nUxH",
        "outputId": "91c018a2-8a6f-4067-d3e3-4a9a18615517"
      },
      "outputs": [],
      "source": [
        "# fetch pluto, foxy version\n",
        "fname = 'https://github.com/duchaba/pluto_happy'\n",
        "!git clone {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Oxsy7GCptb7",
        "outputId": "58bd35e8-36ed-45b8-d031-144a8a24d319"
      },
      "outputs": [],
      "source": [
        "# check to see which disk direction we are at:\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FY3KJNVqF73"
      },
      "outputs": [],
      "source": [
        "# # if not in the correct directory. it can different from /content for you.\n",
        "# import os\n",
        "# f = '/content'\n",
        "# os.chdir(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOs6de4XoH31",
        "outputId": "8b7d0047-2a23-40db-dfa2-251728074a1c"
      },
      "outputs": [],
      "source": [
        "# smoke test it\n",
        "!ls -la pluto_happy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzkHWp-CnU8D"
      },
      "outputs": [],
      "source": [
        "# prompt: pip install requriements.txt\n",
        "\n",
        "#%%capture log_pip_install\n",
        "fname = 'pluto_happy/requirements.txt'\n",
        "!pip install -r {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwaQnDnBxa4F"
      },
      "outputs": [],
      "source": [
        "# print the log file is failed\n",
        "# log_pip_install.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZeBBZZXojkF"
      },
      "outputs": [],
      "source": [
        "# install Pluto\n",
        "fname = 'pluto_happy/pluto.py'\n",
        "%run {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqvaxeavojnY",
        "outputId": "d57c2cf6-cc06-43b2-9353-32a63305535f"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "\n",
        "# wake up Pluto and name it \"monty\". You can choose any name you like.\n",
        "monty = Pluto_Happy('Monty, shares or steel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxuRP5nbojqq",
        "outputId": "b9f684f1-ca82-4096-8a4f-b6a62ec126f1"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "\n",
        "# check out my environments\n",
        "\n",
        "monty.fname_requirements = 'pluto_happy/requirements.txt'\n",
        "monty.print_info_self()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkUKaSNErYt5"
      },
      "outputs": [],
      "source": [
        "help(monty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAg9QSv6hMQm"
      },
      "source": [
        "- The documentation is at: https://platform.openai.com/docs/api-reference\n",
        "\n",
        "- https://github.com/openai/openai-python\n",
        "\n",
        "- The Notebook set to GPU and High RAM, but you do not need them to run. It maybe slow without GPU and a lot of RAM, but it will fine.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYTj6YmpApba"
      },
      "source": [
        "# 🤠 Access to LLM model.\n",
        "---\n",
        "\n",
        "- NOTES: ✋ STOP, define your set of keys before continue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLElZNzgMi8l"
      },
      "source": [
        "## ✋ Define YOUR Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3NPJ7l7nlPF"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BgHE64HMCqi"
      },
      "outputs": [],
      "source": [
        "# Define YOUR key\n",
        "# replace the \"getenv()\" with your key string\n",
        "\n",
        "import os\n",
        "monty._huggingface_key=os.getenv('huggingface_key')\n",
        "monty._kaggle_key=os.getenv('kaggle_key')\n",
        "monty._openai_key=os.getenv('openai_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP0S0-l6YVPi"
      },
      "outputs": [],
      "source": [
        "# # smoke test\n",
        "# prompt: read env key kaggle_key\n",
        "\n",
        "# kaggle_key = os.getenv('kaggle_key')\n",
        "# kaggle_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgCpuPolnmPY"
      },
      "source": [
        "# 🤖 Moderate LLM\n",
        "\n",
        "----\n",
        "\n",
        "- Use OpenAI Moderate model\n",
        "\n",
        "- update to OpenAI 1.x API\n",
        "  - first create a class openai.OpenAI (a client)\n",
        "  - then do the task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSH08CSL96fN"
      },
      "source": [
        "## 🦉 Smoke Test - OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QpszmSJ7AD0"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "\n",
        "# client.moderations.create()\n",
        "\n",
        "ai_client = openai.OpenAI(api_key=monty._openai_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPDm1by88qEb"
      },
      "outputs": [],
      "source": [
        "# help(ai_client.moderations.create)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fLs18n_7AHq"
      },
      "outputs": [],
      "source": [
        "p = \"I am but a sheep who is lost in the wood.\"\n",
        "tmodel = \"text-moderation-latest\"\n",
        "resp = ai_client.moderations.create(input=p, model=tmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoFF_Njb7AQj",
        "outputId": "1428f2e9-309a-4575-bd6d-703482aa1625"
      },
      "outputs": [],
      "source": [
        "# if no response or error then check the \"keys\" section above.\n",
        "resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jNO1cAXNZKr"
      },
      "source": [
        "## 💃 POC - Done\n",
        "---\n",
        "\n",
        "- You just prove the heart of the LLM engine is working.\n",
        "\n",
        "- Technically, you can confidently say the project is \"viable.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HW7lY4ET7zb"
      },
      "source": [
        "# 🪿 Fetch Kaggle Data\n",
        "\n",
        "---\n",
        "- Dataset on kaggle: https://www.kaggle.com/datasets/get2jawa/toxic-comments-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpCcJs0WfigG",
        "outputId": "c3d804c8-7822-4d8a-939b-f4163b31d96e"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW7w62zHfoVM"
      },
      "outputs": [],
      "source": [
        "import opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SysYu5XWTADD"
      },
      "outputs": [],
      "source": [
        "# Function to download dataset from Kaggle website using opendatasets lib.\n",
        "#@add_method(Pluto_Happy)\n",
        "def fetch_kaggle_dataset(dataset_name, path_to_save):\n",
        "\n",
        "  \"\"\"\n",
        "  Downloads a dataset from Kaggle website using opendatasets library.\n",
        "\n",
        "  Args:\n",
        "    dataset_name: (str) The name of the dataset to download.\n",
        "    path_to_save: (str) The path where the dataset will be saved.\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    # Check if the dataset already exists\n",
        "    if os.path.exists(path_to_save):\n",
        "      print(f'Dataset {dataset_name} already exists.')\n",
        "      return\n",
        "\n",
        "    # Download the dataset\n",
        "    print(f'Downloading dataset {dataset_name}...')\n",
        "    opendatasets.download(dataset_name, path_to_save)\n",
        "    print(f'Dataset {dataset_name} downloaded successfully.')\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f'Error downloading dataset {dataset_name}: {e}')\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtovZukFiy8I",
        "outputId": "169e54fd-1db1-410a-fd87-0aace304219b"
      },
      "outputs": [],
      "source": [
        "fname = 'https://www.kaggle.com/competitions/jigsaw-toxic-severity-rating'\n",
        "fetch_kaggle_dataset(fname,'kaggle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWgb7GduiGhq",
        "outputId": "ba82d7ef-4d94-467b-d7db-c365003b24f2"
      },
      "outputs": [],
      "source": [
        "# smoke test it\n",
        "!ls -la kaggle/jigsaw-toxic-severity-rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k3FyCS5T1-N"
      },
      "outputs": [],
      "source": [
        "fname = 'kaggle/jigsaw-toxic-severity-rating/validation_data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "zhqTyIFVT6sT",
        "outputId": "ea6749c2-5e0a-4dec-bee1-382fe8cf89f3"
      },
      "outputs": [],
      "source": [
        "# prompt: load fname csv into dataframe\n",
        "\n",
        "import pandas\n",
        "\n",
        "monty.df_toxic_data = pandas.read_csv(fname)\n",
        "monty.df_toxic_data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bquvd8QUy4M"
      },
      "outputs": [],
      "source": [
        "# prompt: replace \\n with space in the df_toxic_data column less_toxic and more_toxic\n",
        "\n",
        "monty.df_toxic_data['less_toxic'] = monty.df_toxic_data['less_toxic'].str.replace('\\n', ' ')\n",
        "monty.df_toxic_data['more_toxic'] = monty.df_toxic_data['more_toxic'].str.replace('\\n', ' ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Zfyt66nYkxy"
      },
      "outputs": [],
      "source": [
        "# prompt: replace \\n with space in the df_toxic_data column less_toxic and more_toxic\n",
        "\n",
        "monty.df_toxic_data['less_toxic'] = monty.df_toxic_data['less_toxic'].str.replace('http', 'tthp')\n",
        "monty.df_toxic_data['more_toxic'] = monty.df_toxic_data['more_toxic'].str.replace('http', 'tthp')\n",
        "monty.df_toxic_data['less_toxic'] = monty.df_toxic_data['less_toxic'].str.replace('.com', '.no')\n",
        "monty.df_toxic_data['more_toxic'] = monty.df_toxic_data['more_toxic'].str.replace('.com', '.no')\n",
        "monty.df_toxic_data['less_toxic'] = monty.df_toxic_data['less_toxic'].str.replace('.org', '.no')\n",
        "monty.df_toxic_data['more_toxic'] = monty.df_toxic_data['more_toxic'].str.replace('.org', '.no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep4Yw4idVrnO"
      },
      "outputs": [],
      "source": [
        "# prompt: replace any non-printing character with space in the df_toxic_data column less_toxic and more_toxic\n",
        "\n",
        "monty.df_toxic_data['less_toxic'] = monty.df_toxic_data['less_toxic'].str.replace('[^\\\\x00-\\\\x7F]', ' ')\n",
        "monty.df_toxic_data['more_toxic'] = monty.df_toxic_data['more_toxic'].str.replace('[^\\\\x00-\\\\x7F]', ' ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxs-rW7MVLnz"
      },
      "outputs": [],
      "source": [
        "# prompt: set panda row display to be 250 character long\n",
        "\n",
        "pandas.set_option('display.max_colwidth', 550)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "FEoJv6JXT6vF",
        "outputId": "359cc639-007f-4252-fcf7-6345526980ed"
      },
      "outputs": [],
      "source": [
        "monty.df_toxic_data.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzD1v3w3-d0S"
      },
      "outputs": [],
      "source": [
        "t2 = [{'worker': 104, 'less_toxic': '<html><body><ol>\" Why is it insane?<ol>Why is she not linked to from the mkultra article? Her book is not linked to. Nothing. The article uses words such as</ol> <b>\"#9318\"allege\"</b>\". Is your argument entirely based upon calling someone or their information \"\"insane\"\"?\"','more_toxic': '\"<script>Jerk? Me? I seem to recall that you, Bugs & Yankees</script><html>10 were the ones issuing warnings on my talk page. As if your opinion matters more than mine. You make it sound as if \"\"Outfielder\"\" is inaccurrate. I believe that 400+ games in the other outfield positions is enough to show him as an \"\"Outfielder\"\" in his infobox, regardless of his team (by the way, Frank, I\\'m a Mets fan). \"<i>\"Left fielder\"\" is i.noplete. </html>\"'},\n",
        "  {'worker': 720, 'less_toxic': '<b>GOD DAMN IT,<i><table>Not this again. Just so you know, </table><scripts>I have an account too. I guess being blocked for 24 hours didn\\'t teach you anything. I guess we need a source to prove that Wesker killed Sergei.)','more_toxic': 'Troll<b>op Stop fucking your.noputer you meth adicted nazi twat'}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "HMbk97qsAkrf",
        "outputId": "4b4940b8-4409-40fd-85d9-c8a6399abca9"
      },
      "outputs": [],
      "source": [
        "df2 = pandas.DataFrame(t2)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HudGAJuLbJxR",
        "outputId": "f081732e-846a-4743-8c2c-669d8fdf198b"
      },
      "outputs": [],
      "source": [
        "monty.df_toxic_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6LKY6-RuhN3"
      },
      "outputs": [],
      "source": [
        "# prompt: write monty.df_toxic_data dataframe to csv file\n",
        "\n",
        "monty.df_toxic_data.to_csv('toxic_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUaMFR8KvCx8"
      },
      "outputs": [],
      "source": [
        "# # %%write -a app.py\n",
        "\n",
        "# fname = 'toxic_data.csv'\n",
        "# monty.df_toxic_data = pandas.read_csv(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCx5vYanSHsJ"
      },
      "source": [
        "# 🍹 Investigate data\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoFb2lqESJMN"
      },
      "outputs": [],
      "source": [
        "# prompt: create a new column in monty.df_toxic_data dataframe with the word count from \"less_toxic\" column\n",
        "\n",
        "monty.df_toxic_data['less_toxic_word_count'] = monty.df_toxic_data['less_toxic'].apply(lambda x: len(x.split()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "OmDNyQaySJO8",
        "outputId": "23b6a64e-97fd-4d2c-ca0c-39bc00ccbcfd"
      },
      "outputs": [],
      "source": [
        "monty.df_toxic_data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "3iJOe7l-S0N2",
        "outputId": "b24b5187-67c0-4f10-fc80-29ab78b67743"
      },
      "outputs": [],
      "source": [
        "monty.df_toxic_data['more_toxic_word_count'] = monty.df_toxic_data['more_toxic'].apply(lambda x: len(x.split()))\n",
        "monty.df_toxic_data.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZD2gZ2WS0Q2",
        "outputId": "70c25938-4bbb-42d2-adbf-e4b9658a8239"
      },
      "outputs": [],
      "source": [
        "# prompt: find the sum of \"less_toxic_word_count\"\n",
        "\n",
        "lcount = monty.df_toxic_data['less_toxic_word_count'].sum()\n",
        "mcount = monty.df_toxic_data['more_toxic_word_count'].sum()\n",
        "print(lcount + mcount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "AMYaxRFuT5KJ",
        "outputId": "7a85c39a-a391-4dcf-cce8-2c578718dddd"
      },
      "outputs": [],
      "source": [
        "# prompt: using pandas to draw the histogram of \"less_toxic_word_count\"\n",
        "\n",
        "x = monty.df_toxic_data['less_toxic_word_count'].plot.hist(bins=10,\n",
        "  title='Less Toxic Word Count Histogram')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "c8fRmqDXT5N5",
        "outputId": "ad4bbcd1-f20a-4e41-9aed-b518e33e0b94"
      },
      "outputs": [],
      "source": [
        "x = monty.df_toxic_data['more_toxic_word_count'].plot.hist(bins=10,\n",
        "  title='More Toxic Word Count Histogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zQYhB7eS0T_",
        "outputId": "a616df94-4c27-4508-9dff-431cb458b2fd"
      },
      "outputs": [],
      "source": [
        "# prompt: print the max, min, mean, and std of column \"les_toxic_word_count\"\n",
        "\n",
        "max_value = monty.df_toxic_data['less_toxic_word_count'].max()\n",
        "min_value = monty.df_toxic_data['less_toxic_word_count'].min()\n",
        "mean_value = monty.df_toxic_data['less_toxic_word_count'].mean()\n",
        "std_value = monty.df_toxic_data['less_toxic_word_count'].std()\n",
        "\n",
        "print(f\"Max: {max_value}, Min: {min_value}, Mean: {mean_value}, Std: {std_value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOfGf2w_SJSF",
        "outputId": "77d784c6-2973-4bbe-ad86-8f8f85001c4a"
      },
      "outputs": [],
      "source": [
        "# prompt: print the max, min, mean, and std of column \"les_toxic_word_count\"\n",
        "\n",
        "max_value = monty.df_toxic_data['more_toxic_word_count'].max()\n",
        "min_value = monty.df_toxic_data['more_toxic_word_count'].min()\n",
        "mean_value = monty.df_toxic_data['more_toxic_word_count'].mean()\n",
        "std_value = monty.df_toxic_data['more_toxic_word_count'].std()\n",
        "\n",
        "print(f\"Max: {max_value}, Min: {min_value}, Mean: {mean_value}, Std: {std_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzsN-1s2Yt8F"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud\n",
        "import wordcloud\n",
        "# help(wordcloud.WordCloud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRvdUVTzSJU8"
      },
      "outputs": [],
      "source": [
        "# prompt: write a Python function with documentation for drawing a word cloud plot for a dataframe 'less_toxic_word_count'.\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_wordcloud(df, column, title=\"Word Cloud\"):\n",
        "    \"\"\"\n",
        "    Generate a word cloud from text data in a specified DataFrame column.\n",
        "\n",
        "    Args:\n",
        "    df (pd.DataFrame): The DataFrame containing the text data.\n",
        "    column (str): The name of the column containing the text data.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Ensure the column exists in the DataFrame\n",
        "    if column not in df.columns:\n",
        "        print(f\"The column {column} does not exist in the DataFrame.\")\n",
        "        return\n",
        "\n",
        "    # Combine all the text from the column into a single string\n",
        "    text = ' '.join(df[column].astype(str).values)\n",
        "\n",
        "    # create special word stops\n",
        "    my_stop_words = {'page', 'will', 'one', 'edit', 'article', 'know', 'way', 'say'}\n",
        "    combined_set = STOPWORDS.union(my_stop_words)\n",
        "\n",
        "    # Create a WordCloud object and generate the wordcloud\n",
        "    wordcloud = WordCloud(background_color='white', width=800, height=800,\n",
        "      max_words=300, stopwords=combined_set).generate(text)\n",
        "\n",
        "    # Display the generated wordcloud\n",
        "    plt.figure(figsize=(8,8),facecolor = None)\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title)\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.show()\n",
        "\n",
        "    # Save the wordcloud to a file\n",
        "    wordcloud.to_file('wordcloud.png')\n",
        "    return\n",
        "\n",
        "# Example usage:-\n",
        "# generate_wordcloud(result_df, 'Article_Text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "7hL8K0uoW2IM",
        "outputId": "99d4d9b9-0545-4bc9-b692-ddeb51aac1a9"
      },
      "outputs": [],
      "source": [
        "generate_wordcloud(monty.df_toxic_data, \"less_toxic\", \"Less Toxic Word Cloud\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "Wubc9JvSW2LJ",
        "outputId": "c66d0bdb-e98a-4274-b05e-6028e5382d87"
      },
      "outputs": [],
      "source": [
        "generate_wordcloud(monty.df_toxic_data, \"more_toxic\", \"More Toxic Word Cloud\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGDL-RMQW2YX"
      },
      "outputs": [],
      "source": [
        "wordcloud.STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE-02FKebQpL"
      },
      "outputs": [],
      "source": [
        "my_stop_words = {'page', 'will', 'one', 'edit', 'article', 'know', 'way', 'say'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCxGAg8Zca2D"
      },
      "outputs": [],
      "source": [
        "# prompt: combine two sets, wordcloud.STOPWORDS and my_stop_words\n",
        "\n",
        "combined_set = wordcloud.STOPWORDS.union(my_stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usiWUxYtca5R"
      },
      "outputs": [],
      "source": [
        "combined_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNBretL5cbZD"
      },
      "outputs": [],
      "source": [
        "# redraw them by re-run previous generate_wordcloud cell/command."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-TYGDL_AzG7"
      },
      "source": [
        "# 🤖 Update engine\n",
        "\n",
        "---\n",
        "\n",
        "- Write a few functions to make the API and hook into Gradio and Huggingface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpXTPeD_IIFp"
      },
      "outputs": [],
      "source": [
        "# %%writefile -a app.py\n",
        "#\n",
        "# # for openai version 1.3.8\n",
        "@add_method(Pluto_Happy)\n",
        "#\n",
        "def _fetch_moderate_engine(self):\n",
        "  self.ai_client = openai.OpenAI(api_key=self._openai_key)\n",
        "  self.text_model = \"text-moderation-latest\"\n",
        "  return\n",
        "#\n",
        "@add_method(Pluto_Happy)\n",
        "# f\n",
        "def _censor_me(self, p, safer=0.0005):\n",
        "  self._fetch_moderate_engine()\n",
        "  resp_orig = self.ai_client.moderations.create(input=p, model=self.text_model)\n",
        "  resp_dict = resp_orig.model_dump()\n",
        "  #\n",
        "  v1 = resp_dict[\"results\"][0][\"category_scores\"]\n",
        "  max_key = max(v1, key=v1.get)\n",
        "  max_value = v1[max_key]\n",
        "  sum_value = sum(v1.values())\n",
        "  #\n",
        "  v1[\"is_safer_flagged\"] = False\n",
        "  if (max_value >= safer):\n",
        "    v1[\"is_safer_flagged\"] = True\n",
        "  v1[\"is_flagged\"] = resp_dict[\"results\"][0][\"flagged\"]\n",
        "  v1['max_key'] = max_key\n",
        "  v1['max_value'] = max_value\n",
        "  v1['sum_value'] = sum_value\n",
        "  v1['safer_value'] = safer\n",
        "  v1['message'] = p\n",
        "  return v1\n",
        "#\n",
        "@add_method(Pluto_Happy)\n",
        "def _draw_censor(self,data):\n",
        "  self._color_mid_gray = '#6c757d'\n",
        "  exp = (0.01, 0.01)\n",
        "  x = [data['max_value'], (1-data['max_value'])]\n",
        "  title=f\"\\nUnsafe: {data['max_key']}: {(data['max_value']*100):.2f}% Confidence\\n\"\n",
        "  lab = [data['max_key'], 'Other 13 categories']\n",
        "  if (data['is_flagged']):\n",
        "    col=[self.color_danger, self.color_mid_gray]\n",
        "  elif (data['is_safer_flagged']):\n",
        "    col=[self.color_warning, self.color_mid_gray]\n",
        "    lab = ['Relative Score:\\n'+data['max_key'], 'Other 13 categories']\n",
        "    title=f\"\\nPersonal Unsafe: {data['max_key']}: {(data['max_value']*100):.2f}% Confidence\\n\"\n",
        "  else:\n",
        "    col=[self.color_mid_gray, self.color_success]\n",
        "    lab = ['False Negative:\\n'+data['max_key'], 'Other 13 categories']\n",
        "    title='\\nSafe Message\\n'\n",
        "  canvas = self._draw_donut(x, lab, col, exp,title)\n",
        "  return canvas\n",
        "#\n",
        "@add_method(Pluto_Happy)\n",
        "def _draw_donut(self,data,labels,col, exp,title):\n",
        "  # col = [self.color_danger, self._color_secondary]\n",
        "  # exp = (0.01, 0.01)\n",
        "  # Create a pie chart\n",
        "  canvas, pic = matplotlib.pyplot.subplots()\n",
        "  pic.pie(data, explode=exp,\n",
        "    labels=labels,\n",
        "    colors=col,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    textprops={'color':'#0a0a0a'})\n",
        "  # Draw a circle at the center of pie to make it look like a donut\n",
        "  # centre_circle = matplotlib.pyplot.Circle((0,0),0.45,fc='white')\n",
        "  centre_circle = matplotlib.pyplot.Circle((0,0),0.45,fc=col[0],linewidth=2, ec='white')\n",
        "  canvas = matplotlib.pyplot.gcf()\n",
        "  canvas.gca().add_artist(centre_circle)\n",
        "\n",
        "  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "  pic.axis('equal')\n",
        "  pic.set_title(title)\n",
        "  canvas.tight_layout()\n",
        "  # canvas.show()\n",
        "  return canvas\n",
        "#\n",
        "@add_method(Pluto_Happy)\n",
        "# def censor_me(self, msg, safer=0.02, ibutton_1=0):\n",
        "def fetch_toxicity_level(self, msg, safer):\n",
        "  # safer=0.2\n",
        "  yjson = self._censor_me(msg,safer)\n",
        "  _canvas = self._draw_censor(yjson)\n",
        "  _yjson = json.dumps(yjson, indent=4)\n",
        "  # return (_canvas, _yjson)\n",
        "  return(_canvas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50UWtl4KPhCA"
      },
      "outputs": [],
      "source": [
        "# help(matplotlib.pyplot.Circle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC2DivZF4grS"
      },
      "source": [
        "## 🦉 Smoke test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djysBd841sAa",
        "outputId": "babb6ee5-92c5-4ab9-e26c-f1bd238ff30d"
      },
      "outputs": [],
      "source": [
        "# Smoke test\n",
        "resp = monty._censor_me(\"I am but a sheep who is lost in the wood.\")\n",
        "resp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABOp6bgXcTSy"
      },
      "outputs": [],
      "source": [
        "# # prompt: print the first value of monty.df_toxic_data['more_toxic']\n",
        "\n",
        "# monty.df_toxic_data['more_toxic'].values[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFtR4kkHa041",
        "outputId": "14e31b36-7b61-4f60-86d4-97444d9d3914"
      },
      "outputs": [],
      "source": [
        "# tesst with kaggle data\n",
        "msg = str(monty.df_toxic_data['more_toxic'].sample(1).values[0])\n",
        "resp = monty._censor_me(msg)\n",
        "resp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqiP3ho3JbKW"
      },
      "source": [
        "# 🤗 Define HuggingFace Gradio Interface\n",
        "\n",
        "---\n",
        "\n",
        "- Build from scratch using Blocks() instead of the short cut using Interface()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9XhrCVWuP7d"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "# result from a lot of prompt AI and old fashion try and error\n",
        "\n",
        "# print(gradio.__version__)\n",
        "import random\n",
        "\n",
        "def say_hello(val):\n",
        "  return f\"Hello: {val}\"\n",
        "def say_toxic():\n",
        "  return f\"I am toxic\"\n",
        "def fetch_toxic_tweets(maxi=2):\n",
        "    sample_df = monty.df_toxic_data.sample(maxi)\n",
        "    is_true = random.choice([True, False])\n",
        "    c1 = \"more_toxic\"\n",
        "    if is_true:\n",
        "      c1 = \"less_toxic\"\n",
        "    toxic1 = sample_df[c1].iloc[0]\n",
        "    # toxic1 = \"cat eats my homework.\"\n",
        "    return sample_df.to_html(index=False), toxic1\n",
        "#\n",
        "# define all gradio widget/components outside the block for easy to visualize the blocks structure\n",
        "#\n",
        "in1 = gradio.Textbox(lines=3, label=\"Enter Text:\")\n",
        "in2 = gradio.Slider(0.005, .1, value=0.02, step=.005,label=\"Personalize Safer Value: (larger value is less safe)\")\n",
        "out1 = gradio.Plot(label=\"Output:\")\n",
        "out2 = gradio.HTML(label=\"Real-world Toxic Posts/Tweets: *WARNING\")\n",
        "out3 = gradio.Textbox(lines=5, label=\"Output JSON:\")\n",
        "but1 = gradio.Button(\"Measure 14 Toxicity\", variant=\"primary\",size=\"sm\")\n",
        "but2 = gradio.Button(\"Fetch Toxic Text\", variant=\"stop\", size=\"sm\")\n",
        "#\n",
        "txt1 = \"\"\"\n",
        "# 😃 Welcome To The Friendly Text Moderation\n",
        "\n",
        "### Identify 14 categories of text toxicity.\n",
        "\n",
        "> This NLP (Natural Language Processing) AI demonstration aims to prevent profanity, vulgarity, hate speech, violence, sexism, and other offensive language.\n",
        ">It is **not an act of censorship**, as the final UI (User Interface) will give the reader, but not a young reader, the option to click on a label to read the toxic message.\n",
        ">The goal is to create a safer and more respectful environment for you, your colleages, and your family.\n",
        "> This NLP app is 1 of 3 hands-on courses, [\"AI Solution Architect,\" from ELVTR and Duc Haba](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin).\n",
        "---\n",
        "### 🌴 Helpful Instruction:\n",
        "\n",
        "1. Enter your [harmful] message in the input box.\n",
        "\n",
        "2. Click the \"Measure 14 Toxicity\" button.\n",
        "3. View the result on the Donut plot.\n",
        "4. (**Optional**) Click on the \"Fetch Real World Toxic Dataset\" below.\n",
        "5. There are additional options and notes below.\n",
        "\"\"\"\n",
        "txt2 = \"\"\"\n",
        "## 🌻 Author and Developer Notes:\n",
        "---\n",
        "- The demo uses the cutting-edge (2024) AI Natural Language Processing (NLP) model from OpenAI.\n",
        "- This NLP app is 1 of 3 hands-on apps from the [\"AI Solution Architect,\" from ELVTR and Duc Haba](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin).\n",
        "\n",
        "- It is not a Generative (GenAI) model, such as Google Gemini or GPT-4.\n",
        "- The NLP understands the message context, nuance, innuendo, and not just swear words.\n",
        "- We **challenge you** to trick it, i.e., write a toxic tweet or post, but our AI thinks it is safe. If you win, please send us your message.\n",
        "- The 14 toxicity categories are as follows:\n",
        "\n",
        "    1. harassment\n",
        "    2. harassment threatening\n",
        "    3. harassment instructions\n",
        "    4. hate\n",
        "    5. hate threatening\n",
        "    6. hate instructions\n",
        "    7. self harm\n",
        "    8. self harm instructions\n",
        "    9. self harm intent\n",
        "    10. self harm minor\n",
        "    11. sexual\n",
        "    12. sexual minors\n",
        "    13. violence\n",
        "    14. violence graphic\n",
        "\n",
        "- If the NLP model classifies the message as \"safe,\" you can still limit the level of toxicity by using the \"Personal Safe\" slider.\n",
        "- The smaller the personal-safe value, the stricter the limitation. It means that if you're a young or sensitive adult, you should choose a lower personal-safe value, less than 0.02, to ensure you're not exposed to harmful content.\n",
        "- The color of the donut plot is as follows:\n",
        "  - Red is an \"unsafe\" message by the NLP model\n",
        "  - Green is a \"safe\" message\n",
        "  - Yellow is an \"unsafe\" message by your toxicity level\n",
        "\n",
        "- The **\"confidence\"** score refers to the confidence level in detecting a particular type of toxicity among the 14 tracked types. For instance, if the confidence score is 90%, it indicates a 90% chance that the toxicity detected is of that particular type. In comparison, the remaining 13 toxicities collectively have a 10% chance of being the detected toxicity. Conversely, if the confidence score is 3%, it could indicate any toxicity. It's worth noting that the Red, Green, or Yellow safety levels do not influence the confidence score.\n",
        "\n",
        "- The real-world dataset is from the Jigsaw Rate Severity of Toxic Comments on Kaggle. It has 30,108 records.\n",
        "    - Citation:\n",
        "    - Ian Kivlichan, Jeffrey Sorensen, Lucas Dixon, Lucy Vasserman, Meghan Graham, Tin Acosta, Walter Reade. (2021). Jigsaw Rate Severity of Toxic Comments . Kaggle. https://kaggle.com/competitions/jigsaw-toxic-severity-rating\n",
        "- The intent is to share with Duc's friends and colleagues, but for those with nefarious intent, this Text Moderation model is governed by the GNU 3.0 License: https://www.gnu.org/licenses/gpl-3.0.en.html\n",
        "- Author: Copyright (C), 2024 **[Duc Haba](https://linkedin.com/in/duchaba)**\n",
        "---\n",
        "# 🌟 \"AI Solution Architect\" Course by ELVTR\n",
        "\n",
        ">Welcome to the fascinating world of AI and natural language processing (NLP). This NLP model is a part of one of three hands-on application. In our journey together, we will explore the [AI Solution Architect](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin) course, meticulously crafted by ELVTR in collaboration with Duc Haba. This course is intended to serve as your gateway into the dynamic and constantly evolving field of AI Solution Architect, providing you with a comprehensive understanding of its complexities and applications.\n",
        "\n",
        ">An AI Solution Architect (AISA) is a mastermind who possesses a deep understanding of the complex technicalities of AI and knows how to creatively integrate them into real-world solutions. They bridge the gap between theoretical AI models and practical, effective applications. AISA works as a strategist to design AI systems that align with business objectives and technical requirements. They delve into algorithms, data structures, and computational theories to translate them into tangible, impactful AI solutions that have the potential to revolutionize industries.\n",
        "\n",
        "> 🍎 [Sign up for the course today](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin), and I will see you in class.\n",
        "\n",
        "- An article about this NLP Text Moderation will be coming soon.\n",
        "\"\"\"\n",
        "txt3 = \"\"\"\n",
        "## 💥 WARNING: WARNING:\n",
        "---\n",
        "\n",
        "- The following button will retrieve **real-world** offensive posts from Twitter and customer reviews from consumer companies.\n",
        "- The button will display four toxic messages at a time. **Click again** for four more randomly selected postings/tweets.\n",
        "- They contain **profanity, vulgarity, hate, violence, sexism, and other offensive language.**\n",
        "- After you fetch the toxic messages, Click on the **\"Measure 14 Toxicity\" button**.\n",
        "\"\"\"\n",
        "#reverse_button.click(process_text, inputs=text_input, outputs=reversed_text)\n",
        "#\n",
        "\n",
        "with gradio.Blocks() as gradio_app:\n",
        "  # title\n",
        "  gradio.Markdown(txt1) # any html or simple mark up\n",
        "  #\n",
        "  # first row, has two columns 1/3 size and 2/3 size\n",
        "  with gradio.Row():    # items inside rows are columns\n",
        "    # left column\n",
        "    with gradio.Column(scale=1): # items under columns are row, scale is 1/3 size\n",
        "      # left column has two rows, text entry, and buttons\n",
        "      in1.render()\n",
        "      in2.render()\n",
        "      but1.render()\n",
        "      but1.click(monty.fetch_toxicity_level, inputs=[in1, in2], outputs=out1)\n",
        "\n",
        "    with gradio.Column(scale=2):\n",
        "      out1.render()\n",
        "  #\n",
        "  # second row is warning text\n",
        "  with gradio.Row():\n",
        "    gradio.Markdown(txt3)\n",
        "\n",
        "  # third row is fetching toxic data\n",
        "  with gradio.Row():\n",
        "    with gradio.Column(scale=1):\n",
        "      but2.render()\n",
        "      but2.click(fetch_toxic_tweets, inputs=None, outputs=[out2, in1])\n",
        "    with gradio.Column(scale=2):\n",
        "      out2.render()\n",
        "\n",
        "  # fourth row is note text\n",
        "  with gradio.Row():\n",
        "    gradio.Markdown(txt2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3LtVOA5XoQ8"
      },
      "outputs": [],
      "source": [
        "# gradio_app.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzCOApzwIC7V"
      },
      "source": [
        "## 🍒 QA - Test it locally on Jupyter Notebook\n",
        "---\n",
        "\n",
        "- It will failed to test locally if you running VPN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "Adttj_MSuP_y",
        "outputId": "866c0694-0f3d-404e-aa63-8cf27196f4db"
      },
      "outputs": [],
      "source": [
        "# %%write -a app.py\n",
        "# open/launch it\n",
        "gradio_app.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYZQlWzEtmqB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDo1cXLVzVNF"
      },
      "outputs": [],
      "source": [
        "@add_method(Pluto_Happy)\n",
        "def fetch_code_cells(self, notebook_name,\n",
        "  filter_magic=\"# %%write\",\n",
        "  write_to_file=True, fname_override=None):\n",
        "\n",
        "  \"\"\"\n",
        "  Reads a Jupyter notebook (.ipynb file) and writes out all the code cells\n",
        "  that start with the specified magic command to a .py file.\n",
        "\n",
        "  Parameters:\n",
        "  - notebook_name (str): Name of the notebook file (with .ipynb extension).\n",
        "  - filter_magic (str): Magic command filter. Only cells starting with this command will be written.\n",
        "      The defualt is: \"# %%write\"\n",
        "  - write_to_file (bool): If True, writes the filtered cells to a .py file.\n",
        "      Otherwise, prints them to the standard output. The default is True.\n",
        "  - fname_override (str): If provided, overrides the output filename. The default is None.\n",
        "\n",
        "  Returns:\n",
        "  - None: Writes the filtered code cells to a .py file or prints them based on the parameters.\n",
        "\n",
        "  \"\"\"\n",
        "  with open(notebook_name, 'r', encoding='utf-8') as f:\n",
        "    notebook_content = json.load(f)\n",
        "\n",
        "  output_content = []\n",
        "\n",
        "  # Loop through all the cells in the notebook\n",
        "  for cell in notebook_content['cells']:\n",
        "    # Check if the cell type is 'code' and starts with the specified magic command\n",
        "    if cell['cell_type'] == 'code' and cell['source'] and cell['source'][0].startswith(filter_magic):\n",
        "      # Append the source code of the cell to output_content\n",
        "      output_content.append(''.join(cell['source']))\n",
        "\n",
        "  if write_to_file:\n",
        "    if fname_override is None:\n",
        "      # Derive the output filename by replacing .ipynb with .py\n",
        "      output_filename = notebook_name.replace(\".ipynb\", \".py\")\n",
        "    else:\n",
        "      output_filename = fname_override\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "      f.write('\\n'.join(output_content))\n",
        "    print(f'File: {output_filename} written to disk.')\n",
        "  else:\n",
        "    # Print the code cells to the standard output\n",
        "    print('\\n'.join(output_content))\n",
        "    print('-' * 40)  # print separator\n",
        "  return\n",
        "# Example usage:\n",
        "# print_code_cells_from_notebook('your_notebook_name_here.ipynb')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwC_rWcNPkVn"
      },
      "source": [
        "# 🥳 + 🎉: DONE: AI Solution Architect Job Is Done\n",
        "---\n",
        "\n",
        "- As an AI solution architect, your job is technially done.\n",
        "\n",
        "- The rest of the steps are for Deployment Engineer or Backend Solution Architect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anKLQ3g8vlZm"
      },
      "source": [
        "## Write/create required files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE3_ezCcKNjR"
      },
      "outputs": [],
      "source": [
        "# define the huggingface name\n",
        "monty.hface_space = 'duchaba/Friendly_Text_Moderation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn_RtPBoJnIG"
      },
      "outputs": [],
      "source": [
        "# openai: 0.27.7,              Actual: 0.27.7\n",
        "# huggingface_hub: 0.14.1,     Actual: 0.15.1\n",
        "# gradio: 3.32.0,              Actual: 3.32.0\n",
        "# cryptography: 40.0.2,        Actual: 40.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh_AKuSj0tq_",
        "outputId": "64bf0db2-101c-4b2d-e1de-11f61915b568"
      },
      "outputs": [],
      "source": [
        "!cat \"/content/pluto_happy/requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6r8821ktW9Y"
      },
      "outputs": [],
      "source": [
        "# create the requirements.txt file\n",
        "txt = [\"openai\", \"gradio\",\"cryptography\", \"huggingface_hub\", \"psutil\", \"pynvml\", \"py-cpuinfo\", \"flopth\"]\n",
        "monty.write_file(\"requirements.txt\", txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSm8cahGvFxI",
        "outputId": "3bab8aa8-2dcc-4c91-a206-e6ad299b6dde"
      },
      "outputs": [],
      "source": [
        "# optional double check it\n",
        "!cat requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KjPwdG6X1Gz"
      },
      "source": [
        "**STOP**\n",
        "\n",
        "1. Download this notebook\n",
        "\n",
        "1. Upload it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XodnoxcL1m-9",
        "outputId": "3bd6b857-89e2-4605-f9e8-588c3f2c3ac5"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1yKXHVnXCh7",
        "outputId": "16a3ce80-9d25-4f3a-fa67-d7d4bb07e223"
      },
      "outputs": [],
      "source": [
        "fname = \"/content/text_moderation/Text_Moderation.ipynb\"\n",
        "monty.fetch_code_cells(fname, fname_override=\"app_part2.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x-1VYWK2jRD"
      },
      "outputs": [],
      "source": [
        "# prompt: use unix command to concat file1 and file2\n",
        "\n",
        "!cat /content/pluto_happy/pluto.py app_part2.py > app.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDS8KtUEtXAo"
      },
      "outputs": [],
      "source": [
        "# uncomment the %%write code cell about to create app.py\n",
        "# then double check it\n",
        "!cat app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsF4xLdREBx8"
      },
      "source": [
        "## Create the HuggingFace page\n",
        "\n",
        "- Choose a unique file-space, like happy_butterfly\n",
        "\n",
        "- First option, do it on huggingface.com website (recomented)\n",
        "\n",
        "- Second option, do it programatically (optional, uncomment below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dulzFow1AT68"
      },
      "outputs": [],
      "source": [
        "# # second option\n",
        "# api = huggingface_hub.HfApi()\n",
        "# api.create_repo(repo_id=pluto.hface_name, private=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKF1nWC3MRJO"
      },
      "source": [
        "# 🐣 Deploy to HuggingFace Sandbox\n",
        "\n",
        "---\n",
        "\n",
        "- Read the tutorial above if you are confused.\n",
        "\n",
        "- It is easy. \"app.py\" and \"requirements.txt\" are the two files that you need to upload.\n",
        "  - Link to create the app.py file on huggingface web: https://huggingface.co/spaces/duchaba/new/main?filename=app.py\n",
        "\n",
        "- Optional are depending on your more fancy layout/output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPQFNwRXv80u"
      },
      "source": [
        "## Push to files to Hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHfqwn6h7Bgl"
      },
      "outputs": [],
      "source": [
        "@add_method(Pluto_Happy)\n",
        "def _login_hface(self):\n",
        "  huggingface_hub.login(self.decrypt_it(self._huggingface_key),\n",
        "    add_to_git_credential=True) # non-blocking login\n",
        "  self._ph()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGWpv6Sc46Tn",
        "outputId": "08ff40c8-994a-4681-edcc-28dba0a20b22"
      },
      "outputs": [],
      "source": [
        "monty._login_hface()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "054b57dd832740ad9483da8af91fec41",
            "f806b256d9924ce58a7f5eca6e408c51",
            "1a6fbe76da6c4cd3a76a4d1174c6da32",
            "52d2308030cc449090312d52342530b2",
            "1701d6da33be4e7bb9b297808e6a43e0",
            "d4e98388bfdd480aa86dc982e5da6ced",
            "ac269a2fa84d44209fa7933cd3d22547",
            "70400f8568d74961a047ed14f9194d35",
            "0e902acd9b674021b7f42a362d550d85",
            "57dd6539263d468ebbae8ac49598a87f",
            "575da2af2cbe41a5bd674d841446ac48"
          ]
        },
        "id": "yWkJsiH9AT-N",
        "outputId": "f2d5e439-be28-465e-afe1-3995f6de32fc"
      },
      "outputs": [],
      "source": [
        "up_files = [\"app.py\", \"requirements.txt\", \"toxic_data.csv\"]\n",
        "monty.push_hface_files(up_files, hf_space=monty.hface_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXzSFXj-0reI",
        "outputId": "200c0c40-1ee3-471d-9b60-bf540045d949"
      },
      "outputs": [],
      "source": [
        "# test it\n",
        "print(f'https://huggingface.co/spaces/{monty.hface_space}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0BqlE3dGbnq"
      },
      "source": [
        "# 🐢 Pull and Push to Github (Optional)\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** ✋\n",
        "\n",
        "- QA it on this notebook **BEFORE** push it.\n",
        "\n",
        "- If you change any data or files, commit and push it to github. For now, we don't need pull-request, so push it to main or your-branch-name.\n",
        "\n",
        "- I ussualy comment out the section because I don't want to accidental run it (when not ready)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIVSHSwmGbnq",
        "outputId": "a6daf6c8-3f30-4fa3-d5e4-1d6453899fb9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iytF4it5eCt3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "f = '/content'\n",
        "# f = '/content/foxy_cnn_image_classification'\n",
        "os.chdir(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBESQ2AAGbnq",
        "outputId": "fac372d6-4181-46b3-d8a9-a20efd90bf6f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!git branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlvaEHrEGbnr",
        "outputId": "f7fa61ad-4a94-4fd2-e478-c03c9336025a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKnWWmInGbnr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# check for update file\n",
        "!git diff --name-only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWTzuEkld8E6",
        "outputId": "7806f331-f32a-4af2-f92a-8aa90ce866b3"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# f = 'Data-Augmentation-with-Python'\n",
        "# os.chdir(f)\n",
        "!git add -A\n",
        "!git config --global user.email \"duc.haba@gmail.com\"\n",
        "!git config --global user.name \"duchaba\"\n",
        "!git commit -m \"add new predict methods\"\n",
        "# # do the git push in the xterm console\n",
        "# #!git push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMDuDF5gGbnr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # check for any in stage ready to commit\n",
        "# !git diff --name-only --staged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAIl7ZzEGbns",
        "outputId": "9349e9f3-1448-473d-ce6e-9d97ace81987",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# check what were the commits\n",
        "!git log --name-status HEAD^..HEAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Azo-O8pGbnt",
        "outputId": "98189ec2-e164-4d45-8dc3-582e74e5efe0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# double check it before commit\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmPsmXZBuaB3",
        "outputId": "44269845-6f77-4491-a4db-d5ca12da9b6c"
      },
      "outputs": [],
      "source": [
        "!pip install lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU6cc4f4ulGZ",
        "outputId": "22de401c-2543-4c09-d21c-0c30793fe51e"
      },
      "outputs": [],
      "source": [
        "# prompt: git push large file\n",
        "\n",
        "!git-lfs track *.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWaoO8u2Gbnt",
        "outputId": "e9806628-1e16-48bf-9f5d-2125477e7b22",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# push it\n",
        "fname = \"https://duchaba:@github.com/duchaba/pluto_happy.git\"\n",
        "!git push {fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDRDuZL6Mnvt"
      },
      "outputs": [],
      "source": [
        "# !curl https://api.openai.com/v1/moderations \\\n",
        "#   -H \"Content-Type: application/json\" \\\n",
        "#   -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
        "#   -d '{\"input\": \"I want to kill them all.\"}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_jLD0Z7AUKk"
      },
      "source": [
        "# 🕺 That's it. It's dancing time.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUzE7MfOI1Sl"
      },
      "outputs": [],
      "source": [
        "print('the end.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2x-NQlhNSD9"
      },
      "source": [
        "# 🍵 Conclusion\n",
        "\n",
        "- That is it for the NLP text moderation from soup to nuts.\n",
        "\n",
        "- Use this LLM \"as-is\" or as a template to create your own model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VL5egEhI16n",
        "outputId": "a841660a-522c-429e-9642-810dde1c96b6"
      },
      "outputs": [],
      "source": [
        "# monty.print_dancing()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNGSbTLa/QzQtZ8pbrRQ3w1",
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "054b57dd832740ad9483da8af91fec41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f806b256d9924ce58a7f5eca6e408c51",
              "IPY_MODEL_1a6fbe76da6c4cd3a76a4d1174c6da32",
              "IPY_MODEL_52d2308030cc449090312d52342530b2"
            ],
            "layout": "IPY_MODEL_1701d6da33be4e7bb9b297808e6a43e0"
          }
        },
        "0e902acd9b674021b7f42a362d550d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1701d6da33be4e7bb9b297808e6a43e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6fbe76da6c4cd3a76a4d1174c6da32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70400f8568d74961a047ed14f9194d35",
            "max": 25411407,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e902acd9b674021b7f42a362d550d85",
            "value": 25411407
          }
        },
        "52d2308030cc449090312d52342530b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57dd6539263d468ebbae8ac49598a87f",
            "placeholder": "​",
            "style": "IPY_MODEL_575da2af2cbe41a5bd674d841446ac48",
            "value": " 25.4M/25.4M [00:04&lt;00:00, 13.3MB/s]"
          }
        },
        "575da2af2cbe41a5bd674d841446ac48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57dd6539263d468ebbae8ac49598a87f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70400f8568d74961a047ed14f9194d35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac269a2fa84d44209fa7933cd3d22547": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4e98388bfdd480aa86dc982e5da6ced": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f806b256d9924ce58a7f5eca6e408c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4e98388bfdd480aa86dc982e5da6ced",
            "placeholder": "​",
            "style": "IPY_MODEL_ac269a2fa84d44209fa7933cd3d22547",
            "value": "toxic_data.csv: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
